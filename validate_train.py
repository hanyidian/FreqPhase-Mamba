import os
import sys
import glob
import argparse
import torch
from torch.utils.data import DataLoader
from tqdm import tqdm
import numpy as np
import warnings
from collections import namedtuple

# å¿½ç•¥ç‰¹å®šè­¦å‘Š
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning, module="pytorch_wavelets")

# ==============================================================================
# ## CONFIGURATION ##
# ä½ éœ€è¦ä¿®æ”¹çš„æ‰€æœ‰å‚æ•°éƒ½åœ¨è¿™é‡Œ
# ==============================================================================

# ğŸ“Š æœ€ä½³æ¨¡å‹çš„è¯¦ç»†æ€§èƒ½æŒ‡æ ‡:
# ==================================================
#    Dice        : 0.9226
#    Iou         : 0.8581
#    Precision   : 0.9276
#    Recall      : 0.9213
#    F1          : 0.9226
#    Specificity : 0.9812
#    Accuracy    : 0.9746
# ==================================================
# 1. åŒ…å«æ‰€æœ‰.pthæ£€æŸ¥ç‚¹æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„
CHECKPOINTS_DIR = "/root/autodl-tmp/checkpoints/2"

# 2. Hieraæ¨¡å‹æ–‡ä»¶è·¯å¾„
HIERA_PATH = "/root/autodl-tmp/checkpoints/sam2.1_hiera_large.pt"

# 3. æµ‹è¯•æ•°æ®é›†è·¯å¾„
TEST_IMAGE_PATH = "/root/autodl-tmp/datasets/ISIC/test/images"
TEST_MASK_PATH = "/root/autodl-tmp/datasets/ISIC/test/labels"
# TEST_IMAGE_PATH = "/root/autodl-tmp/datasets/Kvasir-SEG/Kvasir-SEG/data/test/images"
# TEST_MASK_PATH = "/root/autodl-tmp/datasets/Kvasir-SEG/Kvasir-SEG/data/test/masks"
# TEST_IMAGE_PATH = "/root/autodl-tmp/datasets/total/ETIS-LaribPolypDB/data/test/im ages"
# TEST_IMAGE_PATH = "/root/autodl-tmp/datasets/CVC-ClinicDB/PNG/data/test/images"
# TEST_MASK_PATH = "/root/autodl-tmp/datasets/CVC-ClinicDB/PNG/data/test/masks"
# TEST_IMAGE_PATH = "/root/autodl-tmp/datasets/total/CVC-300/data/test/images"
# TEST_MASK_PATH = "/root/autodl-tmp/datasets/total/CVC-300/data/test/labels"
# TEST_IMAGE_PATH = "/root/autodl-tmp/datasets/total/CVC-ColonDB/data/test/images"
# TEST_MASK_PATH = "/root/autodl-tmp/datasets/total/CVC-ColonDB/data/test/labels"
# TEST_IMAGE_PATH = "/root/autodl-tmp/datasets/total/ETIS-LaribPolypDB/data/test/images"
# TEST_MASK_PATH = "/root/autodl-tmp/datasets/total/ETIS-LaribPolypDB/data/test/labels"
# 4. æµ‹è¯•å‚æ•°
BATCH_SIZE = 8
IMG_SIZE = 352

# 5. (å¯é€‰) ä¿å­˜å¯è§†åŒ–ç»“æœçš„è·¯å¾„
#    è®¾ç½®ä¸ºä¸€ä¸ªæ–‡ä»¶å¤¹è·¯å¾„ (ä¾‹å¦‚ "/root/autodl-tmp/test_results") æ¥ä¿å­˜å›¾ç‰‡ã€‚
#    è®¾ç½®ä¸º None åˆ™ä¸ä¿å­˜ã€‚
OUTPUT_RESULTS_DIR = None
MAX_TEST_SAMPLES_TO_SAVE = 10  # å¦‚æœä¿å­˜ï¼Œæ¯ä¸ªæ¨¡å‹æœ€å¤šä¿å­˜å¤šå°‘ä¸ªæ ·æœ¬

# ==============================================================================
# ## SCRIPT CODE ##
# ä»è¿™é‡Œå¼€å§‹ï¼Œä½ é€šå¸¸ä¸éœ€è¦ä¿®æ”¹ä»£ç 
# ==============================================================================

# --- åŠ¨æ€æ·»åŠ é¡¹ç›®è·¯å¾„ (å¦‚æœéœ€è¦) ---
# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®ä¸­çš„å…¶ä»–.pyæ–‡ä»¶ (å¦‚æ¨¡å‹å®šä¹‰ã€æ•°æ®é›†ç­‰)
current_dir = os.path.dirname(os.path.abspath(__file__))
# å‡è®¾ models, dataset.py, utils.py ä¸æ­¤è„šæœ¬åœ¨åŒä¸€å±‚çº§æˆ–å¯è®¿é—®
models_dir = os.path.join(current_dir, 'models')
if os.path.exists(models_dir):
    sys.path.insert(0, models_dir)

try:
    from model9 import SAM2UNet
    from dataset import FullDataset
    from utils import compute_metrics, val_collate_fn
    from torchvision.utils import save_image
except ImportError as e:
    print(f"é”™è¯¯: æ— æ³•å¯¼å…¥å¿…è¦çš„æ¨¡å—: {e}")
    print("è¯·ç¡®ä¿ SAM2UNet5.py, dataset.py, utils.py æ–‡ä»¶åœ¨Pythonè·¯å¾„ä¸­ï¼Œæˆ–ä¸æ­¤è„šæœ¬åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")
    sys.exit(1)


def save_test_visual_results(images, masks, preds, batch_indices, output_dir):
    """ä¿å­˜æµ‹è¯•ç»“æœå›¾åƒã€‚"""
    os.makedirs(output_dir, exist_ok=True)
    preds_bin = (torch.sigmoid(preds) > 0.5).float()

    for i in range(images.size(0)):
        img, mask, pred = images[i].cpu(), masks[i].cpu(), preds_bin[i].cpu()
        if img.size(0) == 1: img = img.repeat(3, 1, 1)
        if mask.size(0) == 1: mask = mask.repeat(3, 1, 1)
        if pred.size(0) == 1: pred = pred.repeat(3, 1, 1)

        combined = torch.cat([img, mask, pred], dim=2)
        sample_idx = batch_indices[i] if batch_indices is not None and len(batch_indices) > i else i
        save_image(combined, os.path.join(output_dir, f"test_sample_{sample_idx}_combined.png"))


def run_test_for_checkpoint(args):
    """
    ä¸ºå•ä¸ªæ£€æŸ¥ç‚¹æ‰§è¡Œæµ‹è¯•çš„æ ¸å¿ƒå‡½æ•°ã€‚
    æ¥æ”¶ä¸€ä¸ªåŒ…å«æ‰€æœ‰å‚æ•°çš„å‘½åç©ºé—´å¯¹è±¡ (args)ã€‚
    è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸ã€‚
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 1. åŠ è½½æ¨¡å‹
    model = SAM2UNet(args.hiera_path).to(device)
    checkpoint = torch.load(args.model_path, map_location=device)

    model_state_dict = checkpoint.get('model_state_dict', checkpoint)
    model.load_state_dict(model_state_dict, strict=False)
    model.eval()

    # 2. å‡†å¤‡æµ‹è¯•æ•°æ®é›†
    test_dataset = FullDataset(args.test_image_path, args.test_mask_path, args.img_size, mode='test')
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=2,
                             pin_memory=True, collate_fn=val_collate_fn)

    if not test_dataset:
        print("é”™è¯¯: æµ‹è¯•æ•°æ®é›†ä¸ºç©ºã€‚")
        return None

    # 3. è¿›è¡Œè¯„ä¼°
    metrics_sum = {k: 0 for k in ['dice', 'iou', 'precision', 'recall', 'f1', 'specificity', 'accuracy']}

    with torch.no_grad():
        for batch in tqdm(test_loader, desc=f"Testing {os.path.basename(args.model_path)}", leave=False):
            x, target = batch['image'].to(device), batch['label'].to(device)
            # pred, _, _, = model(x)
            pred, _, _ = model(x)

            batch_metrics = compute_metrics(pred, target)
            for key in metrics_sum:
                metrics_sum[key] += batch_metrics[key]

    if not test_loader:
        print("æ²¡æœ‰æ ·æœ¬è¢«è¯„ä¼°ã€‚")
        return None

    # 4. è®¡ç®—å¹³å‡æŒ‡æ ‡
    num_batches = len(test_loader)
    avg_metrics = {key: value / num_batches for key, value in metrics_sum.items()}

    return avg_metrics


def main():
    """
    ä¸»æ‰§è¡Œå‡½æ•°ï¼šæŸ¥æ‰¾å¹¶è¯„ä¼°æ‰€æœ‰æ£€æŸ¥ç‚¹ï¼Œæ‰¾å‡ºæœ€ä½³æ¨¡å‹ã€‚
    """
    # 1. æŸ¥æ‰¾æ‰€æœ‰.pthæ–‡ä»¶
    checkpoint_paths = glob.glob(os.path.join(CHECKPOINTS_DIR, "*.pth")) + glob.glob(
        os.path.join(CHECKPOINTS_DIR, "*.pt"))

    if not checkpoint_paths:
        print(f"é”™è¯¯ï¼šåœ¨ç›®å½• '{CHECKPOINTS_DIR}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½• .pth æˆ– .pt æ–‡ä»¶ã€‚")
        return

    print(f"åœ¨ '{CHECKPOINTS_DIR}' ä¸­æ‰¾åˆ° {len(checkpoint_paths)} ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œå¼€å§‹é€ä¸€è¯„ä¼°...")
    print("-" * 70)

    best_dice = -1.0
    best_checkpoint_path = None
    best_metrics = None

    # ä½¿ç”¨å‘½åå…ƒç»„åˆ›å»ºä¸€ä¸ªç±»ä¼¼argparseçš„å‚æ•°å¯¹è±¡
    TestArgs = namedtuple('TestArgs', [
        'hiera_path', 'test_image_path', 'test_mask_path', 'batch_size',
        'img_size', 'output_results_dir', 'max_test_samples_to_save', 'model_path'
    ])

    # 2. éå†å¹¶æµ‹è¯•æ¯ä¸ªæ£€æŸ¥ç‚¹
    for i, ckpt_path in enumerate(sorted(checkpoint_paths)):  # sorted()ä¿è¯æµ‹è¯•é¡ºåº
        print(f"[{i + 1}/{len(checkpoint_paths)}] æ­£åœ¨å‡†å¤‡æµ‹è¯•: {os.path.basename(ckpt_path)}")

        current_args = TestArgs(
            hiera_path=HIERA_PATH,
            test_image_path=TEST_IMAGE_PATH,
            test_mask_path=TEST_MASK_PATH,
            batch_size=BATCH_SIZE,
            img_size=IMG_SIZE,
            output_results_dir=OUTPUT_RESULTS_DIR,
            max_test_samples_to_save=MAX_TEST_SAMPLES_TO_SAVE,
            model_path=ckpt_path
        )

        metrics = run_test_for_checkpoint(current_args)

        if metrics is None:
            print(f"æµ‹è¯•å¤±è´¥: {os.path.basename(ckpt_path)}. è·³è¿‡ã€‚")
            print("-" * 70)
            continue

        current_dice = metrics.get('dice', -1.0)
        print(f"âœ… å®Œæˆæµ‹è¯•: {os.path.basename(ckpt_path)} -> Dice Score: {current_dice:.4f}")

        # 3. æ¯”è¾ƒå¹¶è®°å½•æœ€ä½³ç»“æœ
        if current_dice > best_dice:
            print(f"ğŸ† æ–°çš„æœ€ä½³æ¨¡å‹ï¼ Dice: {current_dice:.4f} (ä¹‹å‰æœ€ä½³: {best_dice:.4f})")
            best_dice = current_dice
            best_checkpoint_path = ckpt_path
            best_metrics = metrics

        print("-" * 70)

    # 4. æœ€ç»ˆæŠ¥å‘Š
    if best_checkpoint_path:
        print("\n======================= æœ€ç»ˆè¯„ä¼°å®Œæˆ =======================")
        print(f"ğŸ† æœ€ä½³æ¨¡å‹æ–‡ä»¶æ˜¯: {os.path.basename(best_checkpoint_path)}")
        print(f"   ä½äº: {best_checkpoint_path}")
        print("\nğŸ“Š æœ€ä½³æ¨¡å‹çš„è¯¦ç»†æ€§èƒ½æŒ‡æ ‡:")
        print('=' * 50)
        for key, value in best_metrics.items():
            print(f'   {key.replace("_", " ").capitalize():<12}: {value:.4f}')
        print('=' * 50)
    else:
        print("\næ‰€æœ‰æ£€æŸ¥ç‚¹çš„æµ‹è¯•éƒ½å¤±è´¥äº†æˆ–æ²¡æœ‰æ‰¾åˆ°æ£€æŸ¥ç‚¹ï¼Œæ— æ³•ç¡®å®šæœ€ä½³æ¨¡å‹ã€‚")


if __name__ == "__main__":
    main()
