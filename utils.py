import torch
import torch.nn.functional as F
import os
import random
import matplotlib.pyplot as plt
import torchvision.transforms.functional as TF
from torchvision.utils import save_image
import numpy as np
import warnings

# å¿½ç•¥pytorch_waveletsåº“å¯èƒ½äº§ç”Ÿçš„ç”¨æˆ·è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="pytorch_wavelets")


def save_validation_results(images, masks, preds, epoch, save_path, sample_indices, max_val_samples):
    """
    ä¿å­˜éªŒè¯ç»“æœå›¾åƒï¼ˆåŸå§‹å›¾åƒã€çœŸå®æ©ç ã€é¢„æµ‹æ©ç å’Œç»„åˆå›¾ï¼‰ã€‚
    Args:
        images (Tensor): éªŒè¯å›¾åƒæ‰¹æ¬¡ã€‚
        masks (Tensor): çœŸå®æ©ç æ‰¹æ¬¡ã€‚
        preds (Tensor): æ¨¡å‹é¢„æµ‹ç»“æœæ‰¹æ¬¡ (logits)ã€‚
        epoch (int): å½“å‰è®­ç»ƒepochã€‚
        save_path (str): ä¿å­˜ç»“æœçš„æ ¹ç›®å½•ã€‚
        sample_indices (list or None): æ‰¹æ¬¡ä¸­æ¯ä¸ªæ ·æœ¬åœ¨åŸå§‹æ•°æ®é›†ä¸­çš„ç´¢å¼•ï¼Œç”¨äºå‘½åæ–‡ä»¶ã€‚
        max_val_samples (int): æ¯ä¸ªepochæœ€å¤šä¿å­˜çš„éªŒè¯æ ·æœ¬æ•°é‡ã€‚
    """
    epoch_dir = os.path.join(save_path, f"val_results_epoch_{epoch}")
    os.makedirs(epoch_dir, exist_ok=True)
    preds_bin = (torch.sigmoid(preds) > 0.5).float()  # å°†logitsè½¬æ¢ä¸ºäºŒå€¼é¢„æµ‹

    for i in range(min(images.size(0), max_val_samples)):
        img = images[i].cpu()
        mask = masks[i].cpu()
        pred = preds_bin[i].cpu()

        # ç¡®ä¿å›¾åƒæ˜¯3é€šé“ä»¥ä¾¿ä¿å­˜
        if img.size(0) == 1:  # å¦‚æœæ˜¯ç°åº¦å›¾ï¼Œå¤åˆ¶åˆ°3é€šé“
            img = img.repeat(3, 1, 1)
        if mask.size(0) == 1:
            mask = mask.repeat(3, 1, 1)
        if pred.size(0) == 1:
            pred = pred.repeat(3, 1, 1)

        # ç»„åˆå›¾åƒï¼šåŸå§‹å›¾ | çœŸå®æ©ç  | é¢„æµ‹æ©ç 
        combined = torch.cat([img, mask, pred], dim=2)
        sample_idx = sample_indices[i] if sample_indices is not None and len(sample_indices) > i else i

        save_image(combined, os.path.join(epoch_dir, f"sample_{sample_idx}_combined.png"))
        save_image(img, os.path.join(epoch_dir, f"sample_{sample_idx}_image.png"))
        save_image(mask, os.path.join(epoch_dir, f"sample_{sample_idx}_mask.png"))
        save_image(pred, os.path.join(epoch_dir, f"sample_{sample_idx}_pred.png"))

def _sobel_edge_map(x: torch.Tensor) -> torch.Tensor:
    """
    x: [B,1,H,W] æ¦‚ç‡å›¾æˆ– 0/1 mask
    è¿”å›å½’ä¸€åŒ–åˆ° [0,1] çš„è¾¹ç¼˜å¼ºåº¦å›¾
    """
    B, C, H, W = x.shape
    device, dtype = x.device, x.dtype

    kx = torch.tensor(
        [[-1, 0, 1],
         [-2, 0, 2],
         [-1, 0, 1]], device=device, dtype=dtype
    ).view(1, 1, 3, 3)
    ky = torch.tensor(
        [[-1, -2, -1],
         [ 0,  0,  0],
         [ 1,  2,  1]], device=device, dtype=dtype
    ).view(1, 1, 3, 3)

    gx = F.conv2d(x, kx, padding=1)
    gy = F.conv2d(x, ky, padding=1)
    g = torch.sqrt(gx * gx + gy * gy + 1e-6)

    # æ¯å¼ å›¾å•ç‹¬å½’ä¸€åŒ–ï¼Œé¿å… scale è¿‡å¤§
    g = g / (g.amax(dim=(-1, -2), keepdim=True) + 1e-6)
    return g

def brain_tumor_loss(
    logits,
    targets,
    bce_weight=0.5,
    tversky_weight=0.5,
    pos_weight=2.0,
    alpha=0.3,
    beta=0.7,
    freq_weight=0.02,       # â­ å»ºè®®ï¼š0.01~0.03
    boundary_weight=0.05,   # â­ æ–°å¢ï¼šè¾¹ç•Œä¸€è‡´æ€§æƒé‡ï¼Œå…ˆ 0.03~0.06 è¯•è¯•
    ifm_reg=None,           # å¯ä»¥ä¼  model.get_ifm_reg_loss()
    eps=1e-6,
):
    """
    æ€»æŸå¤± = Dice
          + bce_weight * BCE
          + tversky_weight * Tversky
          + boundary_weight * BoundaryAlignï¼ˆSobel è¾¹ç¼˜ä¸€è‡´æ€§ï¼‰
          + freq_weight * FreqAlignï¼ˆé¢‘åŸŸ log-å¹…åº¦å¯¹é½ï¼Œåé‡ä¸­é«˜é¢‘ï¼‰
          + ifm_regï¼ˆå¯é€‰ï¼‰

    è¯´æ˜ï¼š
      - è¾¹ç•Œé¡¹ä¸»è¦å¸®ä½ è¡¥é«˜é¢‘/è½®å»“ï¼Œå¯¹ decoder é‡Œ high-band æ›´å‹å¥½ï¼›
      - é¢‘åŸŸé¡¹ä¿æŒï¼Œä½†é»˜è®¤æƒé‡ç•¥è°ƒå°ï¼Œé˜²æ­¢å’Œç»“æ„ä¸Šçš„ high-bias å†²çªã€‚
    """

    # ä¸ºäº†åœ¨ AMP ä¸‹ä¹Ÿç¨³å®šï¼Œloss ç»Ÿä¸€ç”¨ float32 è®¡ç®—
    logits = logits.float()
    targets = targets.float()

    # -------- 1. BCEï¼ˆå¸¦å‰æ™¯åŠ æƒï¼‰ --------
    if pos_weight is not None:
        pw = torch.tensor([pos_weight], dtype=logits.dtype, device=logits.device)
        bce = F.binary_cross_entropy_with_logits(logits, targets, pos_weight=pw)
    else:
        bce = F.binary_cross_entropy_with_logits(logits, targets)

    # -------- 2. Soft Dice Loss --------
    probs = torch.sigmoid(logits)               # (B,1,H,W)
    probs_flat   = probs.view(probs.size(0), -1)
    targets_flat = targets.view(targets.size(0), -1)

    intersection = (probs_flat * targets_flat).sum(dim=1)
    denom = probs_flat.sum(dim=1) + targets_flat.sum(dim=1)
    dice = (2.0 * intersection + eps) / (denom + eps)
    dice_loss = 1.0 - dice.mean()

    # -------- 3. Tversky Lossï¼ˆåæƒ© FN â†’ æå‡å°ç›®æ ‡å¬å›ï¼‰ --------
    TP = (probs_flat * targets_flat).sum(dim=1)
    FP = (probs_flat * (1 - targets_flat)).sum(dim=1)
    FN = ((1 - probs_flat) * targets_flat).sum(dim=1)

    tversky_index = (TP + eps) / (TP + alpha * FP + beta * FN + eps)
    tversky_loss = 1.0 - tversky_index.mean()

    seg_loss = dice_loss + bce_weight * bce + tversky_weight * tversky_loss

    # =====================================
    # 4. è¾¹ç•Œä¸€è‡´æ€§æ­£åˆ™ï¼ˆSobel è¾¹ç¼˜ï¼‰BoundaryAlign
    # =====================================
    if boundary_weight > 0.0:
        pred_edge = _sobel_edge_map(probs)
        tgt_edge  = _sobel_edge_map(targets)

        boundary_reg = F.l1_loss(pred_edge, tgt_edge)
    else:
        boundary_reg = logits.new_tensor(0.0)

    # =====================================
    # 5. é¢‘åŸŸå¯¹é½æ­£åˆ™ FreqAlignï¼ˆå¼ºè°ƒä¸­é«˜é¢‘ï¼‰
    # =====================================
    if freq_weight > 0.0:
        # ä¸ºäº†é¿å… AMP å¹²æ‰° FFTï¼Œç”¨ float32 æ˜¾å¼è®¡ç®—
        probs_32 = probs.float()
        targets_32 = targets.float()

        # FFT å¹¶åšä¸­å¿ƒå¹³ç§»ï¼Œä¾¿äºæ„é€ å¾„å‘æƒé‡
        probs_f = torch.fft.fftshift(torch.fft.fft2(probs_32, norm='ortho'))
        target_f = torch.fft.fftshift(torch.fft.fft2(targets_32, norm='ortho'))

        mag_pred = torch.log1p(torch.abs(probs_f))   # [B,1,H,W]
        mag_gt   = torch.log1p(torch.abs(target_f))

        B, C, H, W = mag_pred.shape
        yy, xx = torch.meshgrid(
            torch.arange(H, device=logits.device),
            torch.arange(W, device=logits.device),
            indexing='ij'
        )
        cy, cx = (H - 1) / 2.0, (W - 1) / 2.0
        rr = torch.sqrt((yy - cy) ** 2 + (xx - cx) ** 2)    # [H,W]
        rr = rr / (rr.max() + 1e-6)                         # å½’ä¸€åŒ–åˆ° [0,1]

        # gamma è¶Šå¤§ï¼Œé«˜é¢‘è¶Šé‡ï¼›1.0 ~ 2.0 æ¯”è¾ƒç¨³
        gamma = 1.5
        weight = rr ** gamma                                # [H,W]
        weight = weight[None, None, ...]                    # [1,1,H,W]

        # L1 è·ç¦» + é¢‘ç‡æƒé‡
        freq_reg = F.l1_loss(mag_pred * weight, mag_gt * weight)
    else:
        freq_reg = logits.new_tensor(0.0)

    # -------- 6. æ±‡æ€» --------
    loss = seg_loss \
           + boundary_weight * boundary_reg \
           + freq_weight * freq_reg

    # -------- 7. å¯é€‰ï¼šIFM æ­£åˆ™ï¼ˆæ¥è‡ª model.get_ifm_reg_loss()ï¼‰ --------
    if ifm_reg is not None:
        # ifm_reg è‡ªå·±é‡Œé¢å·²ç»ä¹˜è¿‡ lambda_orth / lambda_entropy
        loss = loss + ifm_reg

    return loss

def compute_metrics(pred, gt):
    """
    è®¡ç®—åŒ»å­¦å›¾åƒåˆ†å‰²çš„å®Œæ•´è¯„ä¼°æŒ‡æ ‡ã€‚
    Args:
        pred (Tensor): æ¨¡å‹é¢„æµ‹çš„logitsã€‚
        gt (Tensor): çœŸå®æ©ç  (0æˆ–1)ã€‚
    Returns:
        dict: åŒ…å«Dice, IoU, Precision, Recall, F1, Specificity, Accuracyçš„å­—å…¸ã€‚
    """
    pred_bin = (torch.sigmoid(pred) > 0.5).float()
    gt = gt.float()

    intersection = (pred_bin * gt).sum()
    union = (pred_bin + gt).sum() - intersection
    pred_sum = pred_bin.sum()
    gt_sum = gt.sum()

    eps = 1e-7  # é¿å…é™¤é›¶

    dice = (2 * intersection) / (pred_sum + gt_sum + eps)
    iou = intersection / (union + eps)

    precision = intersection / (pred_sum + eps)
    recall = intersection / (gt_sum + eps)
    f1 = 2 * precision * recall / (precision + recall + eps)

    total_pixels = pred_bin.numel()
    tn = ((1 - pred_bin) * (1 - gt)).sum()  # True Negatives
    fp = pred_sum - intersection  # False Positives
    fn = gt_sum - intersection  # False Negatives

    specificity = tn / (tn + fp + eps)
    accuracy = (intersection + tn) / (total_pixels + eps)

    return {
        'dice': dice.item(),
        'iou': iou.item(),
        'precision': precision.item(),
        'recall': recall.item(),
        'f1': f1.item(),
        'specificity': specificity.item(),
        'accuracy': accuracy.item()
    }


def validate(model, val_loader, device, epoch, save_path, save_results=True, max_val_samples=20):
    """
    éªŒè¯æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½ï¼Œå¹¶å¯é€‰æ‹©ä¿å­˜éªŒè¯ç»“æœã€‚
    Args:
        model (nn.Module): å¾…éªŒè¯çš„æ¨¡å‹ã€‚
        val_loader (DataLoader): éªŒè¯é›†æ•°æ®åŠ è½½å™¨ã€‚
        device (torch.device): è®¾å¤‡ ('cuda' æˆ– 'cpu')ã€‚
        epoch (int): å½“å‰è®­ç»ƒepoch (ç”¨äºæ–‡ä»¶å‘½å)ã€‚
        save_path (str): ä¿å­˜éªŒè¯ç»“æœå›¾åƒçš„ç›®å½•ã€‚
        save_results (bool): æ˜¯å¦ä¿å­˜éªŒè¯ç»“æœå›¾åƒã€‚
        max_val_samples (int): æ¯ä¸ªepochæœ€å¤šä¿å­˜çš„éªŒè¯æ ·æœ¬æ•°é‡ã€‚
    Returns:
        dict: åŒ…å«å¹³å‡Dice, IoU, Precision, Recall, F1, Specificity, Accuracyçš„å­—å…¸ã€‚
    """
    model.eval()
    metrics_sum = {
        'dice': 0, 'iou': 0, 'precision': 0, 'recall': 0,
        'f1': 0, 'specificity': 0, 'accuracy': 0
    }
    saved_samples_count = 0

    with torch.no_grad():
        for batch_idx, batch in enumerate(val_loader):
            x = batch['image'].to(device)
            target = batch['label'].to(device)
            indices = batch.get('index', None)  # è·å–æ ·æœ¬ç´¢å¼•
            pred, _, _ = model(x)  # åªä½¿ç”¨ä¸»è¾“å‡º
            batch_metrics = compute_metrics(pred, target)
            for key in metrics_sum:
                metrics_sum[key] += batch_metrics[key]

            # å¦‚æœéœ€è¦ä¿å­˜ç»“æœä¸”æœªè¾¾åˆ°æœ€å¤§ä¿å­˜æ•°é‡
            if save_results and saved_samples_count < max_val_samples:
                remaining_slots = max_val_samples - saved_samples_count
                samples_to_save_in_batch = min(x.size(0), remaining_slots)

                if samples_to_save_in_batch > 0:
                    save_validation_results(
                        x[:samples_to_save_in_batch],
                        target[:samples_to_save_in_batch],
                        pred[:samples_to_save_in_batch],
                        epoch,
                        save_path,
                        indices[:samples_to_save_in_batch] if indices is not None else None,
                        samples_to_save_in_batch  # ä¼ å…¥æœ¬æ¬¡éœ€è¦ä¿å­˜çš„æ•°é‡
                    )
                    saved_samples_count += samples_to_save_in_batch

                    # ç¡®ä¿åªä¿å­˜ä¸€æ¬¡ï¼Œå¦‚æœå·²è¾¾åˆ°æœ€å¤§æ•°é‡ï¼Œåˆ™åœæ­¢è¿›ä¸€æ­¥ä¿å­˜
                    if saved_samples_count >= max_val_samples:
                        save_results = False  # å°†æ ‡å¿—è®¾ä¸ºFalseï¼Œä¸å†ä¿å­˜åç»­æ‰¹æ¬¡

    num_batches = len(val_loader)
    avg_metrics = {key: value / num_batches for key, value in metrics_sum.items()}
    return avg_metrics


def plot_training_curve(train_losses, val_metrics, save_path, args):
    fig = plt.figure(figsize=(20, 12))

    # 1. è®­ç»ƒæŸå¤±
    plt.subplot(2, 4, 1)
    plt.plot(train_losses, label='Training Loss', color='red', linewidth=2)
    plt.title('Training Loss Curve', fontsize=12, fontweight='bold')
    plt.xlabel('Iteration')
    plt.ylabel('Loss')
    plt.grid(True, alpha=0.3)
    plt.legend()

    # 2. æ ¸å¿ƒåˆ†å‰²æŒ‡æ ‡
    plt.subplot(2, 4, 2)
    metrics_core = ['dice', 'iou', 'f1']
    colors_core = ['blue', 'green', 'purple']
    for i, metric in enumerate(metrics_core):
        if metric in val_metrics and val_metrics[metric]:
            plt.plot(val_metrics[metric], label=metric.capitalize(),
                     color=colors_core[i], linewidth=2, marker='o', markersize=4)
    plt.title('Core Segmentation Metrics', fontsize=12, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Score')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1)

    # 3. ç²¾ç¡®ç‡å’Œå¬å›ç‡
    plt.subplot(2, 4, 3)
    metrics_pr = ['precision', 'recall']
    colors_pr = ['orange', 'red']
    for i, metric in enumerate(metrics_pr):
        if metric in val_metrics and val_metrics[metric]:
            plt.plot(val_metrics[metric], label=metric.capitalize(),
                     color=colors_pr[i], linewidth=2, marker='s', markersize=4)
    plt.title('Precision & Recall', fontsize=12, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Score')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1)

    # 4. ç‰¹å¼‚åº¦å’Œå‡†ç¡®ç‡
    plt.subplot(2, 4, 4)
    metrics_sa = ['specificity', 'accuracy']
    colors_sa = ['brown', 'gray']
    for i, metric in enumerate(metrics_sa):
        if metric in val_metrics and val_metrics[metric]:
            plt.plot(val_metrics[metric], label=metric.capitalize(),
                     color=colors_sa[i], linewidth=2, marker='^', markersize=4)
    plt.title('Specificity & Accuracy', fontsize=12, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Score')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1)

    # 5. Diceç³»æ•°å•ç‹¬å›¾è¡¨
    plt.subplot(2, 4, 5)
    if 'dice' in val_metrics and val_metrics['dice']:
        plt.plot(val_metrics['dice'], color='blue', linewidth=3, marker='o', markersize=6)
        plt.axhline(y=max(val_metrics['dice']), color='red', linestyle='--', alpha=0.7,
                    label=f'Best: {max(val_metrics["dice"]):.4f}')
    plt.title('Dice Coefficient', fontsize=12, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Dice Score')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1)

    # 6. IoUå•ç‹¬å›¾è¡¨
    plt.subplot(2, 4, 6)
    if 'iou' in val_metrics and val_metrics['iou']:
        plt.plot(val_metrics['iou'], color='green', linewidth=3, marker='s', markersize=6)
        plt.axhline(y=max(val_metrics['iou']), color='red', linestyle='--', alpha=0.7,
                    label=f'Best: {max(val_metrics["iou"]):.4f}')
    plt.title('Intersection over Union', fontsize=12, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('IoU Score')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1)

    # 7. æ‰€æœ‰æŒ‡æ ‡å¯¹æ¯”
    plt.subplot(2, 4, 7)
    metrics_all = ['dice', 'iou', 'precision', 'recall', 'f1']
    colors_all = ['blue', 'green', 'orange', 'red', 'purple']
    for i, metric in enumerate(metrics_all):
        if metric in val_metrics and val_metrics[metric]:
            plt.plot(val_metrics[metric], label=metric.capitalize(),
                     color=colors_all[i], linewidth=2, alpha=0.8)
    plt.title('All Metrics Comparison', fontsize=12, fontweight='bold')
    plt.xlabel('Epoch')
    plt.ylabel('Score')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1)

    # 8. è®­ç»ƒæ¦‚è§ˆ
    plt.subplot(2, 4, 8)
    plt.axis('off')
    overview_text = f"""
ğŸ¥ åŒ»å­¦å½±åƒåˆ†å‰²è®­ç»ƒæ¦‚è§ˆ

ğŸ¯ æ¨¡å‹: SAM2-UNet (å‚æ•°å†»ç»“ä¼˜åŒ–)
âš¡ ä¼˜åŒ–ç­–ç•¥: æ··åˆç²¾åº¦ + å‚æ•°å†»ç»“

ğŸ“ˆ æœ€ä½³æ€§èƒ½æŒ‡æ ‡:
â€¢ Dice: {max(val_metrics.get('dice', [0])):.4f}
â€¢ IoU: {max(val_metrics.get('iou', [0])):.4f}
â€¢ Precision: {max(val_metrics.get('precision', [0])):.4f}
â€¢ Recall: {max(val_metrics.get('recall', [0])):.4f}
â€¢ F1: {max(val_metrics.get('f1', [0])):.4f}
â€¢ Specificity: {max(val_metrics.get('specificity', [0])):.4f}
â€¢ Accuracy: {max(val_metrics.get('accuracy', [0])):.4f}

ğŸ”¬ è®­ç»ƒé…ç½®:
â€¢ Batch Size: {args.batch_size}
â€¢ Learning Rate: {args.lr}
â€¢ Epochs: {args.epoch}
â€¢ Device: {'GPU' if torch.cuda.is_available() else 'CPU'}
"""

    plt.text(0.1, 0.95, overview_text, transform=plt.gca().transAxes,
             fontsize=9, verticalalignment='top', fontfamily='monospace',
             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))

    plt.suptitle('ğŸ¥ SAM2-UNet çœ¼åº•è¡€ç®¡åˆ†å‰²è®­ç»ƒç›‘æ§é¢æ¿', fontsize=16, fontweight='bold', y=0.98)
    plt.tight_layout()
    plt.savefig(os.path.join(save_path, 'training_curve.png'), dpi=300, bbox_inches='tight')
    plt.close()

    print(f"ğŸ“Š è¯¦ç»†è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {os.path.join(save_path, 'training_curve.png')}")


def apply_augmentation(images, masks):
    """
    åº”ç”¨æ•°æ®å¢å¼ºåˆ°å›¾åƒå’Œæ©ç æ‰¹æ¬¡ (ä½¿ç”¨Albumentationså¢å¼ºç­–ç•¥)ã€‚
    Args:
        images (Tensor): åŸå§‹å›¾åƒæ‰¹æ¬¡ [B, C, H, W]ã€‚
        masks (Tensor): åŸå§‹æ©ç æ‰¹æ¬¡ [B, 1, H, W]ã€‚
    Returns:
        tuple: å¢å¼ºåçš„å›¾åƒæ‰¹æ¬¡å’Œæ©ç æ‰¹æ¬¡ã€‚
    """
    try:
        import albumentations as A
    except ImportError:
        print("Albumentations not installed. Please install with: pip install albumentations")
        return images, masks

    # å®šä¹‰å¢å¼ºæµæ°´çº¿ (å¢å¼ºç­–ç•¥ï¼Œä¿æŒç¨³å®š)
    transform = A.Compose([
    A.HorizontalFlip(p=0.6),
    A.VerticalFlip(p=0.6),
    A.Rotate(limit=30, p=0.5),
    A.GaussianBlur(blur_limit=3, p=0.3),
    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),
    # æ–°å¢ï¼šéšæœºå¼¹æ€§å˜å½¢ (ä½å¼ºåº¦ï¼Œä½æ¦‚ç‡)
    A.ElasticTransform(alpha=50, sigma=5, p=0.3),  # æ¸©å’Œå˜å½¢ï¼Œæ¨¡æ‹Ÿç»„ç»‡å˜åŒ–
    # æ–°å¢ï¼šéšæœºGammaè°ƒæ•´ (ä½æ¦‚ç‡)
    # A.RandomGamma(gamma_limit=(90, 110), p=0.2),  # æ¨¡æ‹Ÿç…§æ˜å˜åŒ–
])

    batch_size = images.size(0)
    augmented_images = []
    augmented_masks = []

    for i in range(batch_size):
        # è½¬æ¢ä¸ºAlbumentationsæ ¼å¼: [H, W, C] (å…ˆç§»åˆ°CPU)
        img_np = images[i].cpu().permute(1, 2, 0).numpy()  # [H, W, C]
        mask_np = masks[i].cpu().squeeze().numpy()  # [H, W]

        # åº”ç”¨å¢å¼º
        augmented = transform(image=img_np, mask=mask_np)
        aug_img_np = augmented['image']
        aug_mask_np = augmented['mask']

        # è½¬å›Tensoræ ¼å¼: [C, H, W]
        aug_img = torch.from_numpy(aug_img_np).permute(2, 0, 1).float()
        aug_mask = torch.from_numpy(aug_mask_np).unsqueeze(0).float()

        augmented_images.append(aug_img)
        augmented_masks.append(aug_mask)

    return torch.stack(augmented_images), torch.stack(augmented_masks)


def check_nan_inf(tensor, name):
    """
    æ£€æŸ¥å¼ é‡ä¸­æ˜¯å¦å­˜åœ¨NaNæˆ–Infå€¼ã€‚
    Args:
        tensor (Tensor): è¦æ£€æŸ¥çš„å¼ é‡ã€‚
        name (str): å¼ é‡çš„åç§°ï¼Œç”¨äºæ‰“å°è­¦å‘Šä¿¡æ¯ã€‚
    Returns:
        bool: å¦‚æœå­˜åœ¨NaNæˆ–Infåˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›Falseã€‚
    """
    if torch.isnan(tensor).any() or torch.isinf(tensor).any():
        print(f"WARNING: NaN or Inf detected in {name}")
        return True
    return False


def val_collate_fn(batch):
    """
    éªŒè¯é›†æ•°æ®æ•´ç†å‡½æ•°ï¼Œæ·»åŠ æ ·æœ¬ç´¢å¼•ã€‚
    Args:
        batch (list): åŒ…å«å­—å…¸çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«'image'å’Œ'label'ã€‚
    Returns:
        dict: åŒ…å«'image', 'label', 'index'çš„å­—å…¸ã€‚
    """
    return {
        'image': torch.stack([item['image'] for item in batch]),
        'label': torch.stack([item['label'] for item in batch]),
        'index': [item.get('index', i) for i, item in enumerate(batch)]
    }

